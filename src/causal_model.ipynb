{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "NUM_FEATURES = 0\n",
    "NUM_QUALITY_SCORES = 0\n",
    "\n",
    "\n",
    "# Network that takes in all the input features and outputs a vector of qualities\n",
    "class QualitiesPredictor(nn.Module):\n",
    "    def __init__(self, input_size, num_quality_scores, hidden_layer_sizes):\n",
    "        super(QualitiesPredictor, self).__init__()\n",
    "\n",
    "        # Create input layer\n",
    "        self.input_layer = nn.Linear(input_size, hidden_layer_sizes[0])\n",
    "\n",
    "        # Create hidden layers dynamically based on args\n",
    "        hidden_layers = []\n",
    "        for i in range(1, len(hidden_layer_sizes)):\n",
    "            hidden_size = hidden_layer_sizes[i]\n",
    "            hidden_layers.append(nn.Linear(hidden_layer_sizes[i - 1], hidden_size))\n",
    "        self.hidden_layers = nn.ModuleList(hidden_layers)\n",
    "        self.output_layer = nn.Linear(hidden_layer_sizes[-1], num_quality_scores)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = torch.relu(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Network that takes a quality and the price and predicts the satisfaction\n",
    "class SatisfactionPredictor(nn.Module):\n",
    "    def __init__(self, hidden_layer_sizes):\n",
    "        super(SatisfactionPredictor, self).__init__()\n",
    "\n",
    "        # Create input layer\n",
    "        self.input_layer = nn.Linear(2, hidden_layer_sizes[0])\n",
    "\n",
    "        # Create hidden layers dynamically based on args\n",
    "        hidden_layers = []\n",
    "        for i in range(1, len(hidden_layer_sizes)):\n",
    "            hidden_size = hidden_layer_sizes[i]\n",
    "            hidden_layers.append(nn.Linear(hidden_layer_sizes[i - 1], hidden_size))\n",
    "        self.hidden_layers = nn.ModuleList(hidden_layers)\n",
    "        self.output_layer = nn.Linear(hidden_layer_sizes[-1], 1)\n",
    "\n",
    "    def forward(self, q, p):\n",
    "        x = torch.cat((q, p), dim = 1)\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = torch.relu(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Takes all the quality scores and predicts a total quality variable\n",
    "class TotalQualityPredictor(nn.Module):\n",
    "    def __init__(self, num_quality_scores, hidden_layer_sizes):\n",
    "        super(TotalQualityPredictor, self).__init__()\n",
    "\n",
    "        # Create input layer\n",
    "        self.input_layer = nn.Linear(num_quality_scores, hidden_layer_sizes[0])\n",
    "\n",
    "        # Create hidden layers dynamically based on args\n",
    "        hidden_layers = []\n",
    "        for i in range(1, len(hidden_layer_sizes)):\n",
    "            hidden_size = hidden_layer_sizes[i]\n",
    "            hidden_layers.append(nn.Linear(hidden_layer_sizes[i - 1], hidden_size))\n",
    "        self.hidden_layers = nn.ModuleList(hidden_layers)\n",
    "        self.output_layer = nn.Linear(hidden_layer_sizes[-1], 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.input_layer(x))\n",
    "        for hidden_layer in self.hidden_layers:\n",
    "            x = torch.relu(hidden_layer(x))\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class CausalModel(nn.Module):\n",
    "    def __init__(self, input_size, num_quality_scores, activation_on_quality,\n",
    "                 qualities_predictor_hidden_layer_sizes,\n",
    "                 satisfaction_predictor_hidden_layer_sizes,\n",
    "                 total_quality_predictor_hidden_layer_sizes):\n",
    "        super(CausalModel, self).__init__()\n",
    "\n",
    "        self.num_quality_scores = num_quality_scores\n",
    "\n",
    "        self.qualities_predictor_net = QualitiesPredictor(input_size, num_quality_scores,\n",
    "                                                          qualities_predictor_hidden_layer_sizes)\n",
    "\n",
    "        self.activation_on_quality = activation_on_quality\n",
    "\n",
    "        self.satisfaction_predictors = [\n",
    "            SatisfactionPredictor(satisfaction_predictor_hidden_layer_sizes) for _ in range(num_quality_scores)\n",
    "        ]\n",
    "\n",
    "        self.total_quality_predictor = TotalQualityPredictor(num_quality_scores,\n",
    "                                                             total_quality_predictor_hidden_layer_sizes)\n",
    "\n",
    "        self.total_satisfaction_predictor = SatisfactionPredictor(satisfaction_predictor_hidden_layer_sizes)\n",
    "\n",
    "    def forward(self, x, p):\n",
    "        qualities = self.qualities_predictor_net(x)\n",
    "        qualities = self.activation_on_quality(qualities)\n",
    "\n",
    "        satisfactions = torch.zeros(self.num_quality_scores, 1)\n",
    "        for i, sat_predictor in enumerate(self.satisfaction_predictors):\n",
    "            satisfactions[i] = sat_predictor(qualities[i], p)\n",
    "\n",
    "        total_quality = self.total_quality_predictor(qualities)\n",
    "        total_quality = self.activation_on_quality(total_quality)\n",
    "\n",
    "        total_satisfaction = self.total_satisfaction_predictor(qualities, p)\n",
    "\n",
    "        return satisfactions, total_satisfaction, total_quality\n",
    "\n",
    "    def loss_function(self, satisfactions, total_satisfaction, satisfactions_targets, total_satisfaction_target):\n",
    "        # Define custom loss function\n",
    "        criterion = nn.MSELoss()  # Use Mean Squared Error as the loss criterion\n",
    "        # Compute the loss for satisfactions\n",
    "        loss_satisfactions = criterion(satisfactions, satisfactions_targets)\n",
    "        # Compute the loss for total_satisfaction\n",
    "        loss_total_satisfaction = criterion(total_satisfaction, total_satisfaction_target)\n",
    "        # Add up the losses with appropriate weights (if desired)\n",
    "        total_loss = loss_satisfactions + loss_total_satisfaction\n",
    "\n",
    "        return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CausalDataloader(Dataset):\n",
    "    def __init__(self, path_to_data_dir, transform=None, target_transform=None):\n",
    "        self.data_dir = path_to_data_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        CATEGORIES = [\"staff\", \"facilities\", \"cleanliness\", \"comfort\", \"valueForMoney\", \"location\"]\n",
    "        df = pd.read_csv(\"data.csv\")\n",
    "        X, p = df[[\"stars\", \"reviews\", \"rating\"] + CATEGORIES + list(pd.get_dummies(df[\"city\"]).columns)], df[\"price\"]\n",
    "    \n",
    "        self.data = combined_data\n",
    "        self.labels = combined_labels\n",
    "\n",
    "    def process_data(self, data):\n",
    "        # make sure to add city into the processed data\n",
    "        processed_data = []\n",
    "        label = 0\n",
    "        return processed_data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx, :]\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label\n",
    "# Dataloader class"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Step 1: Load and preprocess your dataset\n",
    "# Assume dataset is loaded and preprocessed, and stored in `data` and `labels` variables\n",
    "\n",
    "data = []\n",
    "s = []\n",
    "total_s = []\n",
    "price = []\n",
    "\n",
    "\n",
    "# Step 2: Split the dataset into train, test, and validation sets\n",
    "# Define the ratio for train, test, and validation sets\n",
    "train_ratio = 0.8\n",
    "test_ratio = 0.1\n",
    "val_ratio = 0.1\n",
    "\n",
    "# Get the number of samples in the dataset\n",
    "num_samples = len(data)\n",
    "\n",
    "# Calculate the number of samples for train, test, and validation sets\n",
    "num_train = int(train_ratio * num_samples)\n",
    "num_test = int(test_ratio * num_samples)\n",
    "num_val = num_samples - num_train - num_test\n",
    "\n",
    "# Shuffle the dataset\n",
    "indices = np.arange(num_samples)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split the dataset into train, test, and validation sets\n",
    "train_data = data[indices[:num_train]]\n",
    "test_data = data[indices[num_train:num_train + num_test]]\n",
    "val_data = data[indices[num_train + num_test:]]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = CausalModel(NUM_FEATURES, NUM_QUALITY_SCORES, nn.Sigmoid, [], [], [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}