{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class HotelDataset(Dataset):\n",
    "    def __init__(self, dataframe, numerical_features):\n",
    "        self.dataframe = dataframe\n",
    "        self.numerical_features = numerical_features\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.dataframe['image'][idx]\n",
    "        image = self.load_image(image_path)\n",
    "        text_reviews = self.dataframe['text_reviews'][idx]\n",
    "        text_description = self.dataframe['text_description'][idx]\n",
    "        numerical_features = self.dataframe[self.numerical_features].iloc[idx].values.astype(np.float32)\n",
    "        label = self.dataframe['price'][idx]\n",
    "        encoded_text_reviews = self.tokenizer(text_reviews, padding='max_length', truncation=True, max_length=128,\n",
    "                                              return_tensors='pt')\n",
    "        encoded_text_description = self.tokenizer(text_description, padding='max_length', truncation=True,\n",
    "                                                   max_length=128, return_tensors='pt')\n",
    "        return {'image': image, 'text_reviews': encoded_text_reviews, 'text_description': encoded_text_description,\n",
    "                'numerical_features': numerical_features, 'label': label}\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        ###############################################################################\n",
    "        # Load image                                                                  #\n",
    "        # and apply any necessary image preprocessing (e.g., resizing, normalization) #\n",
    "        ###############################################################################\n",
    "        image = None\n",
    "        # Your image loading and preprocessing code here\n",
    "        return image\n",
    "\n",
    "\n",
    "class HotelPricePredictionModel(torch.nn.Module):\n",
    "    def __init__(self, cnn_model, transformer1_model, transformer2_model, num_numerical_features, \n",
    "                 cnn_hidden_dim_size, distilbert_hidden_size, hidden_dim=128):\n",
    "        super(HotelPricePredictionModel, self).__init__()\n",
    "        self.cnn_model = cnn_model\n",
    "        self.transformer1_model = transformer1_model\n",
    "        self.transformer2_model = transformer2_model\n",
    "        self.fc1 = torch.nn.Linear(2 * distilbert_hidden_size + cnn_hidden_dim_size + num_numerical_features, hidden_dim)\n",
    "        self.fc2 = torch.nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, image, text_reviews, text_description, numerical_features):\n",
    "        # get the embeddings output by the 3 models\n",
    "        cnn_embed = self.cnn_model(image)\n",
    "        transformer1_embed = self.transformer1_model(**text_reviews)[0]\n",
    "        transformer2_embed = self.transformer2_model(**text_description)[0]\n",
    "        \n",
    "        # reshape them to size (N, 1) for concatenating\n",
    "        cnn_embed = cnn_embed.view(cnn_embed.size(0), -1)\n",
    "        transformer1_embed = transformer1_embed.view(transformer1_embed.size(0), -1)\n",
    "        transformer2_embed = transformer2_embed.view(transformer2_embed.size(0), -1)\n",
    "        \n",
    "        # concatenate embeddings with numerical features and pass through fully connected network\n",
    "        concat_embed = torch.cat([cnn_embed, transformer1_embed, transformer2_embed, numerical_features], dim=1)\n",
    "        \n",
    "        x = torch.relu(self.fc1(concat_embed))\n",
    "        x = self.fc2(x)\n",
    "        return x.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "cnn_path = \"\"\n",
    "review_transformer_path = \"\"\n",
    "description_transformer_path = \"\"\n",
    "numerical_features = []\n",
    "dataframe = pd.read_csv(\"https://raw.githubusercontent.com/john-zhang-uoft/hotel_price_prediction/main/data/final_data.csv\")\n",
    "\n",
    "cnn = torch.load(cnn_path)\n",
    "review_transformer = AutoModelForSequenceClassification.from_pretrained(review_transformer_path)\n",
    "description_transformer = AutoModelForSequenceClassification.from_pretrained(description_transformer_path)\n",
    "\n",
    "cnn_embedding_layer_size = -1\n",
    "transformers_embedding_layer_size = -1\n",
    "\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "# PUT CODE HERE THAT CHANGES CNN, AND THE TRANSFORMERS GETS THE EMBEDDING LAYERS FOR YOUR MODELS\n",
    "########################################################################################\n",
    "########################################################################################\n",
    "\n",
    "dataset = HotelDataset(dataframe, numerical_features)\n",
    "\n",
    "train_data, temp_data = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model = HotelPricePredictionModel(cnn, review_transformer, description_transformer, len(numerical_features), cnn_embedding_layer_size,\n",
    "transformers_embedding_layer_size)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch in tqdm(train_dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False):\n",
    "        image = batch['image'].to(device)\n",
    "        text_reviews = batch['text_reviews'].to(device)\n",
    "        text_description = batch['text_description'].to(device)\n",
    "        numerical_features = batch['numerical_features'].to(device)\n",
    "        label = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(image, text_reviews, text_description, numerical_features)\n",
    "\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * image.size(0) # size of one batch\n",
    "\n",
    "    epoch_loss = running_loss / len(train_data)\n",
    "    train_losses.append(epoch_loss)\n",
    "\n",
    "    model.eval()\n",
    "    running_val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            image = batch['image'].to(device)\n",
    "            text_reviews = batch['text_reviews'].to(device)\n",
    "            text_description = batch['text_description'].to(device)\n",
    "            numerical_features = batch['numerical_features'].to(device)\n",
    "            label = batch['label'].to(device)\n",
    "\n",
    "            output = model(image, text_reviews, text_description, numerical_features)\n",
    "            val_loss = criterion(output, label)\n",
    "            running_val_loss += val_loss.item() * image.size(0)\n",
    "\n",
    "        val_epoch_loss = running_val_loss / len(val_data)\n",
    "        val_losses.append(val_epoch_loss)\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}')\n",
    "\n",
    "# Plot batch and validation loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot batch and validation loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}